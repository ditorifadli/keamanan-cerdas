{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.0+cu121)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas seaborn matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Importing Modules and Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from os import path\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cek ketersediaan GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Importing Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset\n",
    "ctu_attack = pd.read_csv('./Dataset/CTU13_Attack_Traffic.csv')\n",
    "ctu_normal = pd.read_csv('./Dataset/CTU13_Normal_Traffic.csv')\n",
    "unsw_data = pd.read_csv('./Dataset/UNSW_NB15_training-set.csv')\n",
    "\n",
    "# Menambahkan label untuk klasifikasi\n",
    "ctu_attack['label'] = 'ransomware'\n",
    "ctu_normal['label'] = 'normal'\n",
    "\n",
    "# Mapping label 0 dan 1 pada UNSW-NB15 ke 'normal' dan 'ransomware'\n",
    "unsw_data['label'] = unsw_data['label'].replace({0: 'normal', 1: 'ransomware'})\n",
    "\n",
    "# Menggabungkan ketiga dataset\n",
    "data = pd.concat([ctu_attack, ctu_normal, unsw_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>59086131.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12452268.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2408.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.081081</td>\n",
       "      <td>6.726310</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>118741070.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>10.440307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>180643.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>25790.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>24.919872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "0         0.0     59086131.0           7.0           1.0              0.0   \n",
       "1         1.0     12452268.0          37.0           1.0           2408.0   \n",
       "2         2.0    118741070.0           5.0           4.0            170.0   \n",
       "3         3.0       180643.0          25.0          11.0            180.0   \n",
       "4         4.0          440.0           4.0           1.0              0.0   \n",
       "\n",
       "   TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "0              0.0              0.0              0.0          0.000000   \n",
       "1             68.0             68.0             50.0         65.081081   \n",
       "2            682.0             45.0             22.0         34.000000   \n",
       "3          25790.0             90.0              0.0          7.200000   \n",
       "4              0.0              0.0              0.0          0.000000   \n",
       "\n",
       "   Fwd Pkt Len Std  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0         0.000000  ...               NaN               NaN             NaN   \n",
       "1         6.726310  ...               NaN               NaN             NaN   \n",
       "2        10.440307  ...               NaN               NaN             NaN   \n",
       "3        24.919872  ...               NaN               NaN             NaN   \n",
       "4         0.000000  ...               NaN               NaN             NaN   \n",
       "\n",
       "   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0           NaN         NaN               NaN         NaN         NaN   \n",
       "1           NaN         NaN               NaN         NaN         NaN   \n",
       "2           NaN         NaN               NaN         NaN         NaN   \n",
       "3           NaN         NaN               NaN         NaN         NaN   \n",
       "4           NaN         NaN               NaN         NaN         NaN   \n",
       "\n",
       "   is_sm_ips_ports  attack_cat  \n",
       "0              NaN         NaN  \n",
       "1              NaN         NaN  \n",
       "2              NaN         NaN  \n",
       "3              NaN         NaN  \n",
       "4              NaN         NaN  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rows, columns): (267553, 104)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of the datasets\n",
    "print(\"(rows, columns):\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop '-' pada kolom service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Service Distribution in Training Data:\n",
      "service\n",
      "-           94168\n",
      "dns         47294\n",
      "http        18724\n",
      "smtp         5058\n",
      "ftp-data     3995\n",
      "ftp          3428\n",
      "ssh          1302\n",
      "pop3         1105\n",
      "dhcp           94\n",
      "snmp           80\n",
      "ssl            56\n",
      "irc            25\n",
      "radius         12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'service' in data.columns:\n",
    "    print(\"\\nService Distribution in Training Data:\")\n",
    "    print(data['service'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus nilai \"-\" dari data\n",
    "data = data[data['service'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rows, columns): (173385, 104)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of the datasets after drop '-' in service column\n",
    "print(\"(rows, columns):\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: ransomware vs normal:\n",
      "label\n",
      "ransomware    100583\n",
      "normal         72802\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'label' in data.columns:\n",
    "    print(\"Class distribution: ransomware vs normal:\")\n",
    "    class_counts = data['label'].value_counts()\n",
    "    print(class_counts)\n",
    "\n",
    "    # Plot the distribution of classes\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    ax = sns.countplot(data=data, x='label', hue='label', order=class_counts.index, palette='Set2', legend=False)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.title('Ransomware vs Normal (Class Distribution)')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    # Add percentages on top of the bars\n",
    "    total = len(data)\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.1\n",
    "        y = p.get_height() + 5\n",
    "        ax.annotate(percentage, (x, y))\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('./Visualisasi/label_bar_chart.png')\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Encode categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengidentifikasi kolom numerik secara otomatis\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Menghapus kolom 'id' dan target label 'label' dari daftar kolom numerik\n",
    "if 'id' in numerical_cols:\n",
    "    numerical_cols.remove('id')\n",
    "if 'label' in numerical_cols:\n",
    "    numerical_cols.remove('label')\n",
    "\n",
    "# Normalisasi kolom numerik\n",
    "scaler = StandardScaler()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode binary labels\n",
    "bin_data = data.copy()\n",
    "bin_data['label'] = bin_data['label'].apply(lambda x: 'ransomware' if x == 1 else 'normal')\n",
    "le = preprocessing.LabelEncoder()\n",
    "bin_data['label'] = le.fit_transform(bin_data['label'])\n",
    "\n",
    "bin_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X_train = bin_data.drop(columns=['id','label'])\n",
    "y_train = bin_data['label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32) \n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)     \n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)    \n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gunakan CUDA GPU untuk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Classification without Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Karena data cukup besar dan kompleks, maka kami menggunakan Fold 10, Epoch 20 dan default hyperparameters: num_heads=8, embed_dim=256, dropout=0.1, lr=0.001, batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default hyperparameters: num_heads=8, embed_dim=256, dropout=0.1, lr=0.001, batch_size=32\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.5051, Validation Loss: 0.6871, Accuracy: 57.79%, F1 Score: 0.4268\n",
      "Saved best model for fold 1 at epoch 1.\n",
      "Epoch 2/3: Training Loss: 0.5153, Validation Loss: 0.6865, Accuracy: 58.75%, F1 Score: 0.4498\n",
      "Saved best model for fold 1 at epoch 2.\n",
      "Epoch 3/3: Training Loss: 0.6548, Validation Loss: 0.6062, Accuracy: 67.01%, F1 Score: 0.6133\n",
      "Saved best model for fold 1 at epoch 3.\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.3627, Validation Loss: 0.2566, Accuracy: 91.45%, F1 Score: 0.9150\n",
      "Saved best model for fold 2 at epoch 1.\n",
      "Epoch 2/3: Training Loss: 0.3234, Validation Loss: 0.1918, Accuracy: 93.79%, F1 Score: 0.9379\n",
      "Saved best model for fold 2 at epoch 2.\n",
      "Epoch 3/3: Training Loss: 0.1623, Validation Loss: 0.0800, Accuracy: 97.72%, F1 Score: 0.9771\n",
      "Saved best model for fold 2 at epoch 3.\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.1673, Validation Loss: 0.0744, Accuracy: 98.51%, F1 Score: 0.9851\n",
      "Saved best model for fold 3 at epoch 1.\n",
      "Epoch 2/3: Training Loss: 0.4120, Validation Loss: 0.5781, Accuracy: 70.36%, F1 Score: 0.6667\n",
      "Epoch 3/3: Training Loss: 0.4486, Validation Loss: 0.5944, Accuracy: 70.59%, F1 Score: 0.6735\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.2348, Validation Loss: 0.1451, Accuracy: 96.47%, F1 Score: 0.9648\n",
      "Saved best model for fold 4 at epoch 1.\n",
      "Epoch 2/3: Training Loss: 0.2384, Validation Loss: 0.6945, Accuracy: 77.15%, F1 Score: 0.7496\n",
      "Epoch 3/3: Training Loss: 0.2989, Validation Loss: 0.3914, Accuracy: 81.41%, F1 Score: 0.8141\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.2479, Validation Loss: 0.2031, Accuracy: 94.25%, F1 Score: 0.9426\n",
      "Saved best model for fold 5 at epoch 1.\n",
      "Epoch 2/3: Training Loss: 0.1686, Validation Loss: 0.5807, Accuracy: 69.90%, F1 Score: 0.6523\n",
      "Epoch 3/3: Training Loss: 0.3481, Validation Loss: 0.1171, Accuracy: 96.52%, F1 Score: 0.9650\n",
      "Saved best model for fold 5 at epoch 3.\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Fold 1 - Training Loss: 0.6548, Validation Loss: 0.6062, Accuracy: 67.01%, F1 Score: 0.6133\n",
      "Fold 2 - Training Loss: 0.1623, Validation Loss: 0.0800, Accuracy: 97.72%, F1 Score: 0.9771\n",
      "Fold 3 - Training Loss: 0.1673, Validation Loss: 0.0744, Accuracy: 98.51%, F1 Score: 0.9851\n",
      "Fold 4 - Training Loss: 0.2348, Validation Loss: 0.1451, Accuracy: 96.47%, F1 Score: 0.9648\n",
      "Fold 5 - Training Loss: 0.3481, Validation Loss: 0.1171, Accuracy: 96.52%, F1 Score: 0.9650\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Average Metrics:\n",
      "Average Training Loss: 0.3135\n",
      "Average Validation Loss: 0.2046\n",
      "Average Accuracy: 91.25%\n",
      "Average F1 Score: 0.9011\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for All Folds:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       0.90      0.66      0.76     58251\n",
      "  ransomware       0.79      0.95      0.86     80457\n",
      "\n",
      "    accuracy                           0.83    138708\n",
      "   macro avg       0.85      0.80      0.81    138708\n",
      "weighted avg       0.84      0.83      0.82    138708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = le.classes_\n",
    "\n",
    "# Define TransformerModel class without default parameters\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, embed_dim, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Fixed hyperparameters (set to default values)\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(class_names)\n",
    "num_epochs = 3\n",
    "k_folds = 5\n",
    "\n",
    "# Default hyperparameter values\n",
    "num_heads = 8\n",
    "embed_dim = 256\n",
    "dropout = 0.1\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "\n",
    "best_avg_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "model_dir = './Model/Default'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to collect metrics\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "fold_results = []\n",
    "\n",
    "print(f\"Using default hyperparameters: num_heads={num_heads}, embed_dim={embed_dim}, \"\n",
    "      f\"dropout={dropout}, lr={lr}, batch_size={batch_size}\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train_tensor)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Create data loaders for the current fold\n",
    "    train_dataset = TensorDataset(X_train_tensor[train_index], y_train_tensor[train_index])\n",
    "    val_dataset = TensorDataset(X_train_tensor[val_index], y_train_tensor[val_index])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = TransformerModel(input_dim=input_dim, num_classes=num_classes,\n",
    "                             num_heads=num_heads, embed_dim=embed_dim, dropout=dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = None\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        fold_labels = []\n",
    "        fold_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                val_outputs = model(X_val_batch)\n",
    "                val_loss = criterion(val_outputs, y_val_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                fold_labels.extend(y_val_batch.cpu().numpy())\n",
    "                fold_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = accuracy_score(fold_labels, fold_preds) * 100  # Convert to percentage\n",
    "        f1 = f1_score(fold_labels, fold_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_metrics = (avg_train_loss, avg_val_loss, accuracy, f1)\n",
    "            # Save the best model\n",
    "            print(f\"Saved best model for fold {fold + 1} at epoch {epoch + 1}.\")\n",
    "            model_path = os.path.join(model_dir, f\"best_model_fold_{fold + 1}.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    fold_results.append(best_metrics)\n",
    "    all_labels.extend(fold_labels)\n",
    "    all_preds.extend(fold_preds)\n",
    "\n",
    "# Print K-Fold Cross-Validation Results for each fold\n",
    "print(f\"\\nK-Fold Cross-Validation Results:\")\n",
    "for i, result in enumerate(fold_results):\n",
    "    print(f\"Fold {i + 1} - Training Loss: {result[0]:.4f}, Validation Loss: {result[1]:.4f}, \"\n",
    "          f\"Accuracy: {result[2]:.2f}%, F1 Score: {result[3]:.4f}\")\n",
    "\n",
    "# Calculate average metrics across folds\n",
    "avg_train_loss = np.mean([result[0] for result in fold_results])\n",
    "avg_val_loss = np.mean([result[1] for result in fold_results])\n",
    "avg_accuracy = np.mean([result[2] for result in fold_results])\n",
    "avg_f1 = np.mean([result[3] for result in fold_results])\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------')\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}%\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "\n",
    "# Average Confusion Matrix\n",
    "average_conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(average_conf_matrix, annot=True, fmt='.0f', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Average Confusion Matrix Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Classification report for all folds\n",
    "print(\"\\nClassification Report for All Folds:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Find the best Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kemudian menggunakan ParameterGrid untuk mencari dan mengevaluasi Parameter terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 128, 'lr': 0.001, 'num_heads': 4}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.0293, Validation Loss: 0.0716, Accuracy: 98.30%, F1 Score: 0.9830\n",
      "Epoch 2/3: Training Loss: 0.1835, Validation Loss: 0.0472, Accuracy: 98.88%, F1 Score: 0.9888\n",
      "Epoch 3/3: Training Loss: 0.0649, Validation Loss: 0.1867, Accuracy: 94.38%, F1 Score: 0.9431\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.0421, Validation Loss: 0.0465, Accuracy: 98.92%, F1 Score: 0.9891\n",
      "Epoch 2/3: Training Loss: 0.0469, Validation Loss: 0.0212, Accuracy: 99.38%, F1 Score: 0.9938\n",
      "Epoch 3/3: Training Loss: 0.0430, Validation Loss: 0.0489, Accuracy: 98.98%, F1 Score: 0.9898\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.0442, Validation Loss: 0.0948, Accuracy: 98.67%, F1 Score: 0.9868\n",
      "Epoch 2/3: Training Loss: 0.1763, Validation Loss: 0.0871, Accuracy: 98.27%, F1 Score: 0.9827\n",
      "Epoch 3/3: Training Loss: 0.5729, Validation Loss: 0.6121, Accuracy: 69.06%, F1 Score: 0.6535\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.2419, Validation Loss: 0.1421, Accuracy: 96.49%, F1 Score: 0.9647\n",
      "Epoch 2/3: Training Loss: 0.0852, Validation Loss: 0.0534, Accuracy: 98.51%, F1 Score: 0.9851\n",
      "Epoch 3/3: Training Loss: 0.0677, Validation Loss: 0.0752, Accuracy: 98.35%, F1 Score: 0.9835\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.0539, Validation Loss: 0.0196, Accuracy: 99.15%, F1 Score: 0.9915\n",
      "Epoch 2/3: Training Loss: 0.0333, Validation Loss: 0.0449, Accuracy: 98.79%, F1 Score: 0.9878\n",
      "Epoch 3/3: Training Loss: 0.0330, Validation Loss: 0.0253, Accuracy: 99.39%, F1 Score: 0.9939\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.1092, Avg Validation Loss: 0.0457, Avg Accuracy: 98.84%, Avg F1 Score: 0.9884\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 128, 'lr': 0.001, 'num_heads': 8}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.0687, Validation Loss: 0.0461, Accuracy: 98.90%, F1 Score: 0.9890\n",
      "Epoch 2/3: Training Loss: 0.0780, Validation Loss: 0.1025, Accuracy: 97.57%, F1 Score: 0.9758\n",
      "Epoch 3/3: Training Loss: 0.0615, Validation Loss: 0.0434, Accuracy: 98.92%, F1 Score: 0.9892\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.0468, Validation Loss: 0.1169, Accuracy: 96.68%, F1 Score: 0.9666\n",
      "Epoch 2/3: Training Loss: 0.0837, Validation Loss: 0.0663, Accuracy: 98.65%, F1 Score: 0.9865\n",
      "Epoch 3/3: Training Loss: 0.0817, Validation Loss: 0.1098, Accuracy: 97.29%, F1 Score: 0.9728\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.0379, Validation Loss: 0.0247, Accuracy: 99.34%, F1 Score: 0.9934\n",
      "Epoch 2/3: Training Loss: 0.0499, Validation Loss: 0.0503, Accuracy: 98.53%, F1 Score: 0.9853\n",
      "Epoch 3/3: Training Loss: 0.0421, Validation Loss: 0.0351, Accuracy: 98.90%, F1 Score: 0.9890\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.0554, Validation Loss: 0.0465, Accuracy: 98.69%, F1 Score: 0.9869\n",
      "Epoch 2/3: Training Loss: 0.0515, Validation Loss: 0.0481, Accuracy: 98.65%, F1 Score: 0.9865\n",
      "Epoch 3/3: Training Loss: 0.0548, Validation Loss: 0.0798, Accuracy: 96.40%, F1 Score: 0.9642\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.0619, Validation Loss: 0.0645, Accuracy: 98.74%, F1 Score: 0.9874\n",
      "Epoch 2/3: Training Loss: 0.1289, Validation Loss: 0.0576, Accuracy: 98.59%, F1 Score: 0.9859\n",
      "Epoch 3/3: Training Loss: 0.0719, Validation Loss: 0.0604, Accuracy: 98.69%, F1 Score: 0.9869\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.0735, Avg Validation Loss: 0.0477, Avg Accuracy: 98.84%, Avg F1 Score: 0.9884\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 128, 'lr': 0.001, 'num_heads': 16}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.0440, Validation Loss: 0.0145, Accuracy: 99.55%, F1 Score: 0.9955\n",
      "Epoch 2/3: Training Loss: 0.0225, Validation Loss: 0.0152, Accuracy: 99.61%, F1 Score: 0.9961\n",
      "Epoch 3/3: Training Loss: 0.0228, Validation Loss: 0.0167, Accuracy: 99.51%, F1 Score: 0.9951\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.0417, Validation Loss: 0.0155, Accuracy: 99.44%, F1 Score: 0.9944\n",
      "Epoch 2/3: Training Loss: 0.0444, Validation Loss: 0.0146, Accuracy: 99.50%, F1 Score: 0.9950\n",
      "Epoch 3/3: Training Loss: 0.0239, Validation Loss: 0.0246, Accuracy: 99.54%, F1 Score: 0.9953\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.0454, Validation Loss: 0.0143, Accuracy: 99.48%, F1 Score: 0.9948\n",
      "Epoch 2/3: Training Loss: 0.0611, Validation Loss: 0.0487, Accuracy: 98.84%, F1 Score: 0.9884\n",
      "Epoch 3/3: Training Loss: 0.0487, Validation Loss: 0.0629, Accuracy: 98.73%, F1 Score: 0.9873\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.0647, Validation Loss: 0.0396, Accuracy: 99.05%, F1 Score: 0.9905\n",
      "Epoch 2/3: Training Loss: 0.0480, Validation Loss: 0.0430, Accuracy: 99.08%, F1 Score: 0.9908\n",
      "Epoch 3/3: Training Loss: 0.0452, Validation Loss: 0.0289, Accuracy: 99.30%, F1 Score: 0.9930\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.0335, Validation Loss: 0.0091, Accuracy: 99.75%, F1 Score: 0.9975\n",
      "Epoch 2/3: Training Loss: 0.0207, Validation Loss: 0.0148, Accuracy: 99.20%, F1 Score: 0.9920\n",
      "Epoch 3/3: Training Loss: 0.0272, Validation Loss: 0.0218, Accuracy: 99.40%, F1 Score: 0.9940\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.0425, Avg Validation Loss: 0.0163, Avg Accuracy: 99.52%, Avg F1 Score: 0.9952\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 256, 'lr': 0.001, 'num_heads': 4}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.5662, Validation Loss: 0.5659, Accuracy: 65.56%, F1 Score: 0.6358\n",
      "Epoch 2/3: Training Loss: 0.5055, Validation Loss: 0.5759, Accuracy: 67.45%, F1 Score: 0.6664\n",
      "Epoch 3/3: Training Loss: 0.5321, Validation Loss: 0.5752, Accuracy: 66.04%, F1 Score: 0.6475\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.1539, Validation Loss: 0.0556, Accuracy: 98.75%, F1 Score: 0.9875\n",
      "Epoch 2/3: Training Loss: 0.1655, Validation Loss: 0.2312, Accuracy: 92.44%, F1 Score: 0.9248\n",
      "Epoch 3/3: Training Loss: 0.2797, Validation Loss: 0.1771, Accuracy: 88.72%, F1 Score: 0.8879\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.5252, Validation Loss: 0.6816, Accuracy: 57.92%, F1 Score: 0.4252\n",
      "Epoch 2/3: Training Loss: 0.6819, Validation Loss: 0.6805, Accuracy: 57.93%, F1 Score: 0.4250\n",
      "Epoch 3/3: Training Loss: 0.6815, Validation Loss: 0.6820, Accuracy: 57.93%, F1 Score: 0.4250\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.2113, Validation Loss: 0.2312, Accuracy: 92.67%, F1 Score: 0.9271\n",
      "Epoch 2/3: Training Loss: 0.1821, Validation Loss: 0.1836, Accuracy: 95.10%, F1 Score: 0.9506\n",
      "Epoch 3/3: Training Loss: 0.5149, Validation Loss: 0.4144, Accuracy: 81.67%, F1 Score: 0.8172\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.3600, Validation Loss: 0.4784, Accuracy: 72.23%, F1 Score: 0.7137\n",
      "Epoch 2/3: Training Loss: 0.5304, Validation Loss: 0.6780, Accuracy: 58.11%, F1 Score: 0.4271\n",
      "Epoch 3/3: Training Loss: 0.6576, Validation Loss: 0.6710, Accuracy: 58.11%, F1 Score: 0.4271\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.3888, Avg Validation Loss: 0.3928, Avg Accuracy: 77.91%, Avg F1 Score: 0.7425\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 256, 'lr': 0.001, 'num_heads': 8}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.2250, Validation Loss: 0.2214, Accuracy: 93.81%, F1 Score: 0.9375\n",
      "Epoch 2/3: Training Loss: 0.3660, Validation Loss: 0.1649, Accuracy: 95.84%, F1 Score: 0.9585\n",
      "Epoch 3/3: Training Loss: 0.2311, Validation Loss: 0.2275, Accuracy: 93.30%, F1 Score: 0.9321\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.2317, Validation Loss: 0.3305, Accuracy: 85.74%, F1 Score: 0.8578\n",
      "Epoch 2/3: Training Loss: 0.3495, Validation Loss: 0.3102, Accuracy: 86.73%, F1 Score: 0.8678\n",
      "Epoch 3/3: Training Loss: 0.3795, Validation Loss: 0.4874, Accuracy: 70.85%, F1 Score: 0.6721\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.3158, Validation Loss: 0.4933, Accuracy: 78.03%, F1 Score: 0.7779\n",
      "Epoch 2/3: Training Loss: 0.4722, Validation Loss: 0.3641, Accuracy: 86.37%, F1 Score: 0.8645\n",
      "Epoch 3/3: Training Loss: 0.3248, Validation Loss: 0.1755, Accuracy: 95.13%, F1 Score: 0.9515\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.4200, Validation Loss: 0.2633, Accuracy: 90.96%, F1 Score: 0.9102\n",
      "Epoch 2/3: Training Loss: 0.4067, Validation Loss: 0.4606, Accuracy: 74.16%, F1 Score: 0.7391\n",
      "Epoch 3/3: Training Loss: 0.5094, Validation Loss: 0.5366, Accuracy: 66.75%, F1 Score: 0.6486\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.3611, Validation Loss: 0.1996, Accuracy: 94.85%, F1 Score: 0.9485\n",
      "Epoch 2/3: Training Loss: 0.2604, Validation Loss: 0.1799, Accuracy: 95.33%, F1 Score: 0.9534\n",
      "Epoch 3/3: Training Loss: 0.2453, Validation Loss: 0.1772, Accuracy: 95.05%, F1 Score: 0.9503\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.3411, Avg Validation Loss: 0.2182, Avg Accuracy: 92.74%, Avg F1 Score: 0.9277\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 256, 'lr': 0.001, 'num_heads': 16}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.4853, Validation Loss: 0.3692, Accuracy: 85.68%, F1 Score: 0.8576\n",
      "Epoch 2/3: Training Loss: 0.2296, Validation Loss: 0.1052, Accuracy: 97.52%, F1 Score: 0.9752\n",
      "Epoch 3/3: Training Loss: 0.0933, Validation Loss: 0.0823, Accuracy: 98.05%, F1 Score: 0.9805\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.0745, Validation Loss: 0.0574, Accuracy: 98.46%, F1 Score: 0.9846\n",
      "Epoch 2/3: Training Loss: 0.2563, Validation Loss: 0.8897, Accuracy: 76.95%, F1 Score: 0.7477\n",
      "Epoch 3/3: Training Loss: 0.4596, Validation Loss: 0.3409, Accuracy: 83.94%, F1 Score: 0.8399\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.1240, Validation Loss: 0.0679, Accuracy: 98.56%, F1 Score: 0.9856\n",
      "Epoch 2/3: Training Loss: 0.0984, Validation Loss: 0.0690, Accuracy: 98.54%, F1 Score: 0.9854\n",
      "Epoch 3/3: Training Loss: 0.1570, Validation Loss: 0.0936, Accuracy: 97.44%, F1 Score: 0.9743\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.1701, Validation Loss: 0.1346, Accuracy: 96.72%, F1 Score: 0.9670\n",
      "Epoch 2/3: Training Loss: 0.1378, Validation Loss: 0.1225, Accuracy: 96.73%, F1 Score: 0.9671\n",
      "Epoch 3/3: Training Loss: 0.0954, Validation Loss: 0.0575, Accuracy: 98.58%, F1 Score: 0.9857\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.1554, Validation Loss: 0.0713, Accuracy: 98.62%, F1 Score: 0.9862\n",
      "Epoch 2/3: Training Loss: 0.0929, Validation Loss: 0.3257, Accuracy: 89.06%, F1 Score: 0.8873\n",
      "Epoch 3/3: Training Loss: 0.0811, Validation Loss: 0.0494, Accuracy: 98.78%, F1 Score: 0.9878\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.0937, Avg Validation Loss: 0.0629, Avg Accuracy: 98.49%, Avg F1 Score: 0.9848\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 512, 'lr': 0.001, 'num_heads': 4}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.5689, Validation Loss: 0.5357, Accuracy: 64.64%, F1 Score: 0.6209\n",
      "Epoch 2/3: Training Loss: 0.5860, Validation Loss: 0.6820, Accuracy: 57.86%, F1 Score: 0.4242\n",
      "Epoch 3/3: Training Loss: 0.6815, Validation Loss: 0.6839, Accuracy: 57.86%, F1 Score: 0.4242\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.6914, Validation Loss: 0.6836, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Epoch 2/3: Training Loss: 0.6825, Validation Loss: 0.6817, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Epoch 3/3: Training Loss: 0.6820, Validation Loss: 0.6812, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.4921, Validation Loss: 0.5407, Accuracy: 64.79%, F1 Score: 0.6232\n",
      "Epoch 2/3: Training Loss: 0.5419, Validation Loss: 0.5373, Accuracy: 64.38%, F1 Score: 0.6177\n",
      "Epoch 3/3: Training Loss: 0.5445, Validation Loss: 0.5431, Accuracy: 63.68%, F1 Score: 0.6087\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.6688, Validation Loss: 0.6796, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Epoch 2/3: Training Loss: 0.6828, Validation Loss: 0.6803, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Epoch 3/3: Training Loss: 0.6765, Validation Loss: 0.6798, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.6434, Validation Loss: 0.6713, Accuracy: 58.33%, F1 Score: 0.4332\n",
      "Epoch 2/3: Training Loss: 0.6453, Validation Loss: 0.6756, Accuracy: 58.11%, F1 Score: 0.4271\n",
      "Epoch 3/3: Training Loss: 0.6816, Validation Loss: 0.6824, Accuracy: 58.11%, F1 Score: 0.4271\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.6210, Avg Validation Loss: 0.6210, Avg Accuracy: 60.69%, Avg F1 Score: 0.5050\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 512, 'lr': 0.001, 'num_heads': 8}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.5731, Validation Loss: 0.6493, Accuracy: 52.58%, F1 Score: 0.4746\n",
      "Epoch 2/3: Training Loss: 0.6747, Validation Loss: 0.6810, Accuracy: 57.86%, F1 Score: 0.4242\n",
      "Epoch 3/3: Training Loss: 0.6790, Validation Loss: 0.6820, Accuracy: 57.86%, F1 Score: 0.4242\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.6640, Validation Loss: 0.6813, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Epoch 2/3: Training Loss: 0.6826, Validation Loss: 0.6823, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Epoch 3/3: Training Loss: 0.6818, Validation Loss: 0.6812, Accuracy: 57.91%, F1 Score: 0.4247\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.6835, Validation Loss: 0.7205, Accuracy: 43.19%, F1 Score: 0.2846\n",
      "Epoch 2/3: Training Loss: 0.6807, Validation Loss: 0.6848, Accuracy: 57.93%, F1 Score: 0.4250\n",
      "Epoch 3/3: Training Loss: 0.6821, Validation Loss: 0.6805, Accuracy: 57.93%, F1 Score: 0.4250\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.5868, Validation Loss: 0.6190, Accuracy: 67.43%, F1 Score: 0.6190\n",
      "Epoch 2/3: Training Loss: 0.6826, Validation Loss: 0.6796, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Epoch 3/3: Training Loss: 0.6822, Validation Loss: 0.6915, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.5688, Validation Loss: 0.5650, Accuracy: 70.44%, F1 Score: 0.6994\n",
      "Epoch 2/3: Training Loss: 0.6004, Validation Loss: 0.5812, Accuracy: 58.11%, F1 Score: 0.4271\n",
      "Epoch 3/3: Training Loss: 0.5538, Validation Loss: 0.5425, Accuracy: 63.61%, F1 Score: 0.6084\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.6155, Avg Validation Loss: 0.6345, Avg Accuracy: 59.89%, Avg F1 Score: 0.5104\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Evaluating params: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 512, 'lr': 0.001, 'num_heads': 16}\n",
      "Fold 1/5\n",
      "Epoch 1/3: Training Loss: 0.3079, Validation Loss: 0.5048, Accuracy: 68.76%, F1 Score: 0.6724\n",
      "Epoch 2/3: Training Loss: 0.3844, Validation Loss: 0.2558, Accuracy: 90.07%, F1 Score: 0.9008\n",
      "Epoch 3/3: Training Loss: 0.5181, Validation Loss: 0.5414, Accuracy: 65.93%, F1 Score: 0.6097\n",
      "Fold 2/5\n",
      "Epoch 1/3: Training Loss: 0.2446, Validation Loss: 0.3092, Accuracy: 88.28%, F1 Score: 0.8835\n",
      "Epoch 2/3: Training Loss: 0.3036, Validation Loss: 0.3776, Accuracy: 84.02%, F1 Score: 0.8412\n",
      "Epoch 3/3: Training Loss: 0.3670, Validation Loss: 0.3674, Accuracy: 84.69%, F1 Score: 0.8476\n",
      "Fold 3/5\n",
      "Epoch 1/3: Training Loss: 0.5743, Validation Loss: 0.5478, Accuracy: 65.50%, F1 Score: 0.6321\n",
      "Epoch 2/3: Training Loss: 0.6384, Validation Loss: 0.6795, Accuracy: 58.00%, F1 Score: 0.4581\n",
      "Epoch 3/3: Training Loss: 0.6371, Validation Loss: 0.6051, Accuracy: 60.28%, F1 Score: 0.5795\n",
      "Fold 4/5\n",
      "Epoch 1/3: Training Loss: 0.5551, Validation Loss: 0.5600, Accuracy: 66.90%, F1 Score: 0.6590\n",
      "Epoch 2/3: Training Loss: 0.5431, Validation Loss: 0.6807, Accuracy: 58.21%, F1 Score: 0.4283\n",
      "Epoch 3/3: Training Loss: 0.5446, Validation Loss: 0.3365, Accuracy: 86.44%, F1 Score: 0.8650\n",
      "Fold 5/5\n",
      "Epoch 1/3: Training Loss: 0.4122, Validation Loss: 0.3383, Accuracy: 85.12%, F1 Score: 0.8519\n",
      "Epoch 2/3: Training Loss: 0.3946, Validation Loss: 0.2650, Accuracy: 92.80%, F1 Score: 0.9275\n",
      "Epoch 3/3: Training Loss: 0.5118, Validation Loss: 0.5278, Accuracy: 66.40%, F1 Score: 0.6444\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Avg Training Loss: 0.4285, Avg Validation Loss: 0.3429, Avg Accuracy: 84.62%, Avg F1 Score: 0.8418\n",
      "--------------------------------------------------------------------------------------------------\n",
      "\n",
      "Result:\n",
      "\n",
      "Best hyperparameters: {'batch_size': 32, 'dropout': 0.1, 'embed_dim': 128, 'lr': 0.001, 'num_heads': 16}\n",
      "Best average validation loss: 0.0163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Model definition without default parameters\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, embed_dim, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "\n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.output_layer = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transform input to embeddings\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Apply transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Dropout before fully connected layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output layer (final classification)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "class_names = le.classes_\n",
    "\n",
    "# Hyperparameters grid\n",
    "param_grid = {\n",
    "    'num_heads': [4, 8, 16],\n",
    "    'embed_dim': [128, 256, 512],\n",
    "    'dropout': [0.1],\n",
    "    'lr': [1e-3],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "\n",
    "# Fixed hyperparameters\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(class_names)\n",
    "num_epochs = 3\n",
    "k_folds = 5\n",
    "\n",
    "best_avg_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Evaluating params: {params}\")\n",
    "    \n",
    "    fold_results = []\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train_tensor)):\n",
    "        print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "        # Create data loaders for the current fold\n",
    "        train_dataset = TensorDataset(X_train_tensor[train_index], y_train_tensor[train_index])\n",
    "        val_dataset = TensorDataset(X_train_tensor[val_index], y_train_tensor[val_index])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "        # Initialize the model, criterion, and optimizer\n",
    "        model = TransformerModel(input_dim=input_dim, num_classes=num_classes,\n",
    "                                 num_heads=params['num_heads'], embed_dim=params['embed_dim'], dropout=params['dropout']).to(device)  \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_metrics = None\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for X_val_batch, y_val_batch in val_loader:\n",
    "                    X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)  \n",
    "                    val_outputs = model(X_val_batch)\n",
    "                    val_loss = criterion(val_outputs, y_val_batch)\n",
    "                    total_val_loss += val_loss.item()\n",
    "\n",
    "                    # Collect predictions and labels for metrics\n",
    "                    _, preds = torch.max(val_outputs, 1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(y_val_batch.cpu().numpy())\n",
    "\n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            accuracy = accuracy_score(all_labels, all_preds) * 100  # Convert to percentage\n",
    "            f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss: {avg_train_loss:.4f}, \"\n",
    "                  f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")\n",
    "\n",
    "            # Save the best model based on validation loss\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_metrics = (avg_train_loss, avg_val_loss, accuracy, f1)\n",
    "\n",
    "        fold_results.append(best_metrics)\n",
    "\n",
    "    avg_train_loss = np.mean([result[0] for result in fold_results])\n",
    "    avg_val_loss = np.mean([result[1] for result in fold_results])\n",
    "    avg_accuracy = np.mean([result[2] for result in fold_results])\n",
    "    avg_f1 = np.mean([result[3] for result in fold_results])\n",
    "\n",
    "    print(f\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Avg Training Loss: {avg_train_loss:.4f}, Avg Validation Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Avg Accuracy: {avg_accuracy:.2f}%, Avg F1 Score: {avg_f1:.4f}\")\n",
    "    print('--------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    if avg_val_loss < best_avg_val_loss:\n",
    "        best_avg_val_loss = avg_val_loss\n",
    "        best_params = params\n",
    "\n",
    "print(f\"\\nResult:\")\n",
    "print(f\"\\nBest hyperparameters: {best_params}\")\n",
    "print(f\"Best average validation loss: {best_avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpan Hyperparameters Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best hyperparameters to a text file\n",
    "output_folder = './Hyperparameters'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file_path = os.path.join(output_folder, 'best_hyperparameters.txt')\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(f\"Best hyperparameters: {best_params}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Classification with Tuning (Best Hyperparameters)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kemudian membuat model dengan Hyperparameters terbaik dan disimpan ke dalam Folder ./Model/Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default hyperparameters: num_heads=16, embed_dim=128, dropout=0.1, lr=0.001, batch_size=32\n",
      "Fold 1/5\n",
      "Epoch 1/10: Training Loss: 0.0444, Validation Loss: 0.0154, Accuracy: 99.55%, F1 Score: 0.9955\n",
      "Saved best model for fold 1 at epoch 1.\n",
      "Epoch 2/10: Training Loss: 0.0398, Validation Loss: 0.0346, Accuracy: 99.01%, F1 Score: 0.9900\n",
      "Epoch 3/10: Training Loss: 0.0368, Validation Loss: 0.0327, Accuracy: 99.39%, F1 Score: 0.9939\n",
      "Epoch 4/10: Training Loss: 0.0315, Validation Loss: 0.0221, Accuracy: 99.48%, F1 Score: 0.9948\n",
      "Epoch 5/10: Training Loss: 0.0278, Validation Loss: 0.0196, Accuracy: 99.19%, F1 Score: 0.9919\n",
      "Epoch 6/10: Training Loss: 0.0376, Validation Loss: 0.0209, Accuracy: 99.43%, F1 Score: 0.9943\n",
      "Epoch 7/10: Training Loss: 0.0259, Validation Loss: 0.0202, Accuracy: 99.50%, F1 Score: 0.9950\n",
      "Epoch 8/10: Training Loss: 0.0203, Validation Loss: 0.0117, Accuracy: 99.66%, F1 Score: 0.9966\n",
      "Saved best model for fold 1 at epoch 8.\n",
      "Epoch 9/10: Training Loss: 0.0263, Validation Loss: 0.0200, Accuracy: 99.44%, F1 Score: 0.9944\n",
      "Epoch 10/10: Training Loss: 0.0257, Validation Loss: 0.0108, Accuracy: 99.64%, F1 Score: 0.9964\n",
      "Saved best model for fold 1 at epoch 10.\n",
      "Fold 2/5\n",
      "Epoch 1/10: Training Loss: 0.0492, Validation Loss: 0.0247, Accuracy: 98.95%, F1 Score: 0.9895\n",
      "Saved best model for fold 2 at epoch 1.\n",
      "Epoch 2/10: Training Loss: 0.0492, Validation Loss: 0.0459, Accuracy: 98.73%, F1 Score: 0.9873\n",
      "Epoch 3/10: Training Loss: 0.0411, Validation Loss: 0.0283, Accuracy: 98.97%, F1 Score: 0.9896\n",
      "Epoch 4/10: Training Loss: 0.0391, Validation Loss: 0.0289, Accuracy: 99.35%, F1 Score: 0.9935\n",
      "Epoch 5/10: Training Loss: 0.0379, Validation Loss: 0.0453, Accuracy: 98.89%, F1 Score: 0.9889\n",
      "Epoch 6/10: Training Loss: 0.0353, Validation Loss: 0.0272, Accuracy: 99.16%, F1 Score: 0.9916\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 94\u001b[0m\n\u001b[0;32m     92\u001b[0m X_val_batch, y_val_batch \u001b[38;5;241m=\u001b[39m X_val_batch\u001b[38;5;241m.\u001b[39mto(device), y_val_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     93\u001b[0m val_outputs \u001b[38;5;241m=\u001b[39m model(X_val_batch)\n\u001b[1;32m---> 94\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m val_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Collect predictions and labels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_names = le.classes_\n",
    "\n",
    "# Define TransformerModel class without default parameters\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_heads, embed_dim, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_layer = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Fixed hyperparameters (set to default values)\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "num_classes = len(class_names)\n",
    "num_epochs = 10\n",
    "k_folds = 5\n",
    "\n",
    "# Default hyperparameter values\n",
    "num_heads = 16\n",
    "embed_dim = 128\n",
    "dropout = 0.1\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "\n",
    "best_avg_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "model_dir = './Model/Best'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to collect metrics\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "fold_results = []\n",
    "\n",
    "print(f\"Using Best Hyperparameters: batch_size={batch_size}, dropout={dropout}, lr={lr} \"\n",
    "      f\"embed_dim={embed_dim}, num_heads={num_heads}\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train_tensor)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Create data loaders for the current fold\n",
    "    train_dataset = TensorDataset(X_train_tensor[train_index], y_train_tensor[train_index])\n",
    "    val_dataset = TensorDataset(X_train_tensor[val_index], y_train_tensor[val_index])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = TransformerModel(input_dim=input_dim, num_classes=num_classes,\n",
    "                             num_heads=num_heads, embed_dim=embed_dim, dropout=dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = None\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        fold_labels = []\n",
    "        fold_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                val_outputs = model(X_val_batch)\n",
    "                val_loss = criterion(val_outputs, y_val_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                _, preds = torch.max(val_outputs, 1)\n",
    "                fold_labels.extend(y_val_batch.cpu().numpy())\n",
    "                fold_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = accuracy_score(fold_labels, fold_preds) * 100  # Convert to percentage\n",
    "        f1 = f1_score(fold_labels, fold_preds, average='weighted')\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}: Training Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_metrics = (avg_train_loss, avg_val_loss, accuracy, f1)\n",
    "            # Save the best model\n",
    "            print(f\"Saved best model for fold {fold + 1} at epoch {epoch + 1}.\")\n",
    "            model_path = os.path.join(model_dir, f\"best_model_fold_{fold + 1}.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    fold_results.append(best_metrics)\n",
    "    all_labels.extend(fold_labels)\n",
    "    all_preds.extend(fold_preds)\n",
    "\n",
    "# Print K-Fold Cross-Validation Results for each fold\n",
    "print(f\"\\nK-Fold Cross-Validation Results:\")\n",
    "for i, result in enumerate(fold_results):\n",
    "    print(f\"Fold {i + 1} - Training Loss: {result[0]:.4f}, Validation Loss: {result[1]:.4f}, \"\n",
    "          f\"Accuracy: {result[2]:.2f}%, F1 Score: {result[3]:.4f}\")\n",
    "\n",
    "# Calculate average metrics across folds\n",
    "avg_train_loss = np.mean([result[0] for result in fold_results])\n",
    "avg_val_loss = np.mean([result[1] for result in fold_results])\n",
    "avg_accuracy = np.mean([result[2] for result in fold_results])\n",
    "avg_f1 = np.mean([result[3] for result in fold_results])\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------')\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}%\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")\n",
    "\n",
    "# Average Confusion Matrix\n",
    "average_conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(average_conf_matrix, annot=True, fmt='.0f', cmap='Blues', cbar=False,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Average Confusion Matrix Across Folds')\n",
    "plt.show()\n",
    "\n",
    "# Classification report for all folds\n",
    "print(\"\\nClassification Report for All Folds:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
